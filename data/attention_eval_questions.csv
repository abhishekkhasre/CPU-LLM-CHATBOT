question,reference_answer
What is the main idea behind the paper 'Attention is All You Need'?,"The paper proposes the Transformer architecture, which relies entirely on attention mechanisms, eliminating recurrence entirely and enabling more parallelization."
What is the Transformer architecture?,The Transformer is a neural network architecture based solely on self-attention mechanisms. It processes input sequences in parallel and uses encoder-decoder layers without any recurrence.
How does the self-attention mechanism work in the Transformer?,"Self-attention allows each word in a sequence to attend to all other words, computing a weighted sum based on learned attention scores derived from queries, keys, and values."
What is the purpose of positional encoding in Transformers?,"Since Transformers lack recurrence, positional encoding is added to input embeddings to give the model information about the relative or absolute position of tokens in the sequence."
How is multi-head attention different from single-head attention?,"Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions, improving its ability to model relationships."
What are the main components of the Transformer encoder?,"The encoder consists of a stack of identical layers, each containing two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network."
What are the main components of the Transformer decoder?,"Each decoder layer has three sub-layers: masked multi-head self-attention, multi-head attention over encoder output, and a feed-forward network."
Why is masking used in the decoder's self-attention?,Masking prevents positions from attending to subsequent positions to preserve the auto-regressive property during training.
What is layer normalization in the Transformer?,Layer normalization is applied after each sub-layer to stabilize and accelerate training by normalizing the input layer-wise.
What is residual connection in the Transformer model?,"Residual connections are added around each sub-layer, followed by layer normalization, helping with gradient flow and convergence."
What are the benefits of the Transformer over RNNs?,"Transformers enable parallel computation, have shorter paths between dependencies, and are more efficient to train compared to RNNs and LSTMs."
What dataset was used to evaluate the Transformer model?,The Transformer was evaluated on English-to-German and English-to-French translation tasks using the WMT 2014 datasets.
What optimizer was used to train the Transformer?,The Adam optimizer was used with specific beta values and a custom learning rate schedule.
How many layers were used in the base Transformer model?,The base model uses 6 layers each for the encoder and decoder.
How does the learning rate schedule work in the Transformer?,"The learning rate increases linearly for warm-up steps, then decreases proportionally to the inverse square root of the step number."
What is label smoothing and why is it used?,Label smoothing is a regularization technique that prevents the model from becoming over-confident by softening the target distribution.
"How are queries, keys, and values computed in self-attention?","They are computed by multiplying the input by learned projection matrices Wq, Wk, and Wv respectively."
What is the purpose of the feed-forward network in each layer?,"The feed-forward network applies two linear transformations with a ReLU activation in between, applied independently to each position."
How does the Transformer perform compared to previous models?,The Transformer outperforms previous models like GNMT on BLEU scores and trains significantly faster.
Why does the Transformer model generalize better?,"Due to its architecture, the Transformer captures long-range dependencies more effectively and is less prone to vanishing gradients."
What role does attention play in sequence transduction tasks?,Attention helps the model focus on relevant parts of the input sequence when generating each token in the output.
What is the dimension of embeddings in the base model?,The base model uses embeddings of size 512 for all layers and components.
Why are embeddings scaled by sqrt(d_model)?,To avoid large dot-product values which can push softmax into regions with very small gradients.
What is shared between the input and output embeddings?,"The same weight matrix is shared between the input and output embedding layers, and the pre-softmax linear transformation."
How are position-wise feed-forward networks implemented?,"They apply two linear transformations with a ReLU activation in between, independently to each position."
What are the different attention heads capturing?,Each attention head captures different aspects or patterns of relationships between words.
Why did the authors eliminate recurrence?,To improve parallelization and training speed without sacrificing model performance.
How does the Transformer handle long sequences?,"Self-attention allows the model to directly connect distant positions in the sequence, efficiently handling long dependencies."
How does beam search affect translation quality?,Beam search helps generate higher-quality translations by exploring multiple possible outputs at each decoding step.
What is the final output layer in the Transformer decoder?,A linear transformation followed by a softmax function that predicts the probability distribution over the target vocabulary.
